{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Doc Classification.ipynb","provenance":[{"file_id":"1J0YPIZ7ADPof6M2AIgDD1hmTwKEXSjtU","timestamp":1583472633708},{"file_id":"130igEs5W2JoWILOyDCITTV6DIYHtqY_E","timestamp":1583203906436},{"file_id":"1Oei4kVWfB_Oqwh9oxMdLxsRYOt1rp7cD","timestamp":1583121408998}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1M3C7KW9WYvLo7qfkVsTYCHm46BZUuWDE","authorship_tag":"ABX9TyMYHswdNA3BC6EEB5hi52QF"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"HqTnM5CWTA2Y","colab":{"base_uri":"https://localhost:8080/","height":663},"outputId":"a7e98d33-e710-42e9-e01b-b149bba1d902","executionInfo":{"status":"error","timestamp":1583832575033,"user_tz":-330,"elapsed":7357,"user":{"displayName":"Chinchili NagaGayathri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBwe3rdcMMP7AYp4wt-watfkQXNaXTZsR5jnmS=s64","userId":"00972754971743836265"}}},"source":["import en_core_web_sm\n","nlp = en_core_web_sm.load()\n","import nltk\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","import re\n","import pandas as pd\n","import numpy as np\n","from time import time \n","import multiprocessing\n","from gensim.models import Word2Vec\n","from sklearn.manifold import TSNE\n","from sklearn.model_selection import train_test_split\n","\n","#file_name = 'document_classification\\Resume1.txt'\n","#mat=[][2]\n","import os\n","\n","\n","main=[]\n","#print(files)\n","for i in os.listdir(\"/content/drive/My Drive/resume/Training & Test/Resume\"):\n","     if i != \".ipynb_checkpoints\":\n","      x=i\n","      try:\n","        fname = open(\"/content/drive/My Drive/resume/Training & Test/Resume/\"+x).read()\n","      except UnicodeDecodeError:\n","         continue\n","        \n","      f1=re.sub(r'\\W+', ' ',fname)\n","    \n","      wordnet_lemmatizer = WordNetLemmatizer()\n","    \n","      words = nltk.word_tokenize(f1)\n","    \n","      f2=\" \"\n","      for w in words:\n","          f2=f2+\" \"+wordnet_lemmatizer.lemmatize(w)\n","    \n","      doc = nlp(f2)\n","    \n","      tokens = [token.text for token in doc if not token.is_stop]\n","    \n","      l=[]\n","      l.append(tokens)\n","      l.append(\"1\")\n","      main.append(l)\n","\n","for i in os.listdir(\"/content/drive/My Drive/resume/Training & Test/Non Resume\"):\n","     if i != \".ipynb_checkpoints\":\n","       x=i\n","       try:\n","          fname = open(\"/content/drive/My Drive/resume/Training & Test/Non Resume/\"+x).read()\n","       except UnicodeDecodeError:\n","          continue\n","        \n","       f1=re.sub(r'\\W+', ' ',fname)\n","       wordnet_lemmatizer = WordNetLemmatizer()\n","       words = nltk.word_tokenize(f1)\n","       f2=\" \"\n","       for w in words:\n","           f2=f2+\" \"+wordnet_lemmatizer.lemmatize(w)\n","       doc = nlp(f2)\n","    \n","       tokens = [token.text for token in doc if not token.is_stop]\n","      \n","       l=[]\n","       l.append(tokens)\n","       l.append(\"0\")\n","       main.append(l)\n","\n","\n","\n","df = pd.DataFrame(main, columns = ['Tokens', 'Label'])\n","\n","\n","\n","\n","\n"],"execution_count":2,"outputs":[{"output_type":"error","ename":"LookupError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-4d13f0f81f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mwordnet_lemmatizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n    - ''\n**********************************************************************\n"]}]},{"cell_type":"code","metadata":{"id":"l28_Q3_IjmGe","colab_type":"code","outputId":"b2a7d6e0-b734-4334-e650-11d7dcd78d11","executionInfo":{"status":"ok","timestamp":1583488264174,"user_tz":-330,"elapsed":1767,"user":{"displayName":"Chinchili NagaGayathri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBwe3rdcMMP7AYp4wt-watfkQXNaXTZsR5jnmS=s64","userId":"00972754971743836265"}},"colab":{"base_uri":"https://localhost:8080/","height":331}},"source":["\n","pred = []\n","for i in os.listdir(\"/content/drive/My Drive/resume/Prediction/Resume\"):\n","    if i != \".ipynb_checkpoints\":\n","      x=i\n","      try:\n","        fname = open(\"/content/drive/My Drive/resume/Prediction/Resume/\"+x).read()\n","      except UnicodeDecodeError:\n","        continue\n","        \n","      f1=re.sub(r'\\W+', ' ',fname)\n","      wordnet_lemmatizer = WordNetLemmatizer()\n","      words = nltk.word_tokenize(f1)\n","      f2=\" \"\n","      for w in words:\n","          f2=f2+\" \"+wordnet_lemmatizer.lemmatize(w)\n","      doc = nlp(f2)\n","   \n","      tokens = [token.text for token in doc if not token.is_stop]\n","    \n","      l=[]\n","      l.append(tokens)\n","      pred.append(l)\n","\n","print(len(pred))\n","\n","for i in os.listdir(\"/content/drive/My Drive/resume/Prediction/Non Resume\"):\n","    if i != \".ipynb_checkpoints\":\n","      x=i\n","      try:\n","          fname = open(\"/content/drive/My Drive/resume/Prediction/Non Resume/\"+x).read()\n","      except UnicodeDecodeError:\n","          continue\n","          \n","      f1=re.sub(r'\\W+', ' ',fname)\n","      wordnet_lemmatizer = WordNetLemmatizer()\n","      words = nltk.word_tokenize(f1)\n","      f2=\" \"\n","      for w in words:\n","          f2=f2+\" \"+wordnet_lemmatizer.lemmatize(w)\n","      doc = nlp(f2)\n","    \n","      tokens = [token.text for token in doc if not token.is_stop]\n","      \n","      l=[]\n","      l.append(tokens)\n","      pred.append(l)\n","\n","print(len(pred))\n","\n","df_pred = pd.DataFrame(pred, columns=['Tokens'])\n","df_pred"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4\n","8\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[  , Computer, Science, Faculty, New, Delhi, D...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[  , Isabelle, Smith, rn, cphon, Sometown, TX,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[  , Don, t, know, begin, Click, link, resume,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[  , Don, t, know, begin, Click, link, resume,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[  , BIODATA, G, Pranathi, 8143958515, 16wh1a0...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>[  , PAYMENT, RECEIPT, Guest, Sanjay, Date, 31...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>[  , Jax, Sampson, 111, 789, 3456, jax, sampso...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>[  , Cody, Fredrickson, 123, 456, 7891, cfredr...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              Tokens\n","0  [  , Computer, Science, Faculty, New, Delhi, D...\n","1  [  , Isabelle, Smith, rn, cphon, Sometown, TX,...\n","2  [  , Don, t, know, begin, Click, link, resume,...\n","3  [  , Don, t, know, begin, Click, link, resume,...\n","4  [  , BIODATA, G, Pranathi, 8143958515, 16wh1a0...\n","5  [  , PAYMENT, RECEIPT, Guest, Sanjay, Date, 31...\n","6  [  , Jax, Sampson, 111, 789, 3456, jax, sampso...\n","7  [  , Cody, Fredrickson, 123, 456, 7891, cfredr..."]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"em5cKGYBkGOV","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"TH5DsNhckGJT","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"pZI5eCz7_yUL","colab_type":"code","outputId":"804fb23e-c852-414c-f7c1-31dbdadffabe","executionInfo":{"status":"ok","timestamp":1583493154383,"user_tz":-330,"elapsed":966885,"user":{"displayName":"Chinchili NagaGayathri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBwe3rdcMMP7AYp4wt-watfkQXNaXTZsR5jnmS=s64","userId":"00972754971743836265"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["cores = multiprocessing.cpu_count() \n","w2v_model = Word2Vec(min_count=20,\n","                     window=2,\n","                     size=1000,\n","                     sample=6e-5, \n","                     alpha=0.03, \n","                     min_alpha=0.0007, \n","                     negative=20,\n","                     workers=cores-1)\n","\n","t = time()\n","\n","print(w2v_model.corpus_count)\n","w2v_model.build_vocab(df[\"Tokens\"], progress_per=1000)\n","print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n","\n","w2v_model.train(df[\"Tokens\"], total_examples=w2v_model.corpus_count, epochs=10000, report_delay=1)\n","print(w2v_model.corpus_count)\n","\n","print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n","Time to build vocab: 0.0 mins\n","194\n","Time to train the model: 16.09 mins\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6JsmKsCu6QGP","colab_type":"code","outputId":"c58bd21f-4093-402d-f41d-745bb1ef75b6","executionInfo":{"status":"ok","timestamp":1583490701196,"user_tz":-330,"elapsed":1531,"user":{"displayName":"Chinchili NagaGayathri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBwe3rdcMMP7AYp4wt-watfkQXNaXTZsR5jnmS=s64","userId":"00972754971743836265"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["from sklearn.manifold import TSNE\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import scale\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics import confusion_matrix\n","\n","y = df['Label'].values\n","X = np.array(df[\"Tokens\"])\n","\n","#And here is the train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n","\n","\n","vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)\n","\n","matrix = vectorizer.fit_transform([x for x in X_train])\n","\n","tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n","print ('vocab size :', len(tfidf))\n","\n","def buildWordVector(tokens, size):\n","    vec = np.zeros(size).reshape((1, size))\n","    \n","    count = 0.\n","    for word in tokens:\n","        try:\n","    \n","            vec += w2v_model[word].reshape((1, size)) * tfidf[word]\n","            print(w2v_model[word])\n","            count += 1.\n","        except KeyError: # handling the case where the token is not\n","                         # in the corpus. useful for testing.\n","            continue\n","    if count != 0:\n","        vec /= count\n","    \n","    \n","    return vec\n","\n","train_vecs_w2v = np.concatenate([buildWordVector(z, 1000) for z in map(lambda x: x, X_train)])\n","\n","\n","test_vecs_w2v = np.concatenate([buildWordVector(z, 1000) for z in map(lambda x: x, X_test)])\n","train_vecs_w2v = scale(train_vecs_w2v)\n","\n","\n","test_vecs_w2v = scale(test_vecs_w2v)\n","\n","print(test_vecs_w2v)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["vocab size : 639\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"],"name":"stderr"},{"output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_qEgCPSc6QKb","colab_type":"code","outputId":"7a9a4ca2-2225-44b9-a5b3-aa1b3e19c016","executionInfo":{"status":"ok","timestamp":1583490512750,"user_tz":-330,"elapsed":970,"user":{"displayName":"Chinchili NagaGayathri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBwe3rdcMMP7AYp4wt-watfkQXNaXTZsR5jnmS=s64","userId":"00972754971743836265"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["\n","\n","X_pred = np.array(df_pred[\"Tokens\"])\n","\n","\n","pred_vec_w2v = np.concatenate([buildWordVector(z, 1000) for z in map(lambda x: x, X_pred)])\n","pred_vec_w2v = scale(pred_vec_w2v)\n","\n","print(pred_vec_w2v)\n","\n","print ('shape for training set : ',train_vecs_w2v.shape,\n","      '\\nshape for test set : ', test_vecs_w2v.shape,\n","       '\\nshape for predicted set : ', pred_vec_w2v.shape,) \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[-0.99728757  0.22012779  0.28329361 ...  2.31811969  1.29675151\n","   1.93578235]\n"," [-1.08099882 -2.12974629  1.80628943 ... -1.12633679 -2.04906944\n","   0.39463985]\n"," [ 1.11533768  0.97517249 -1.37097711 ... -0.69088525  0.30290978\n","  -0.61131167]\n"," ...\n"," [-0.7938815  -0.86028872  0.72150687 ...  0.62846081  0.55708205\n","   0.80772044]\n"," [ 0.34164224 -0.18166186 -0.79304318 ...  0.02268002 -0.41036219\n","  -0.34792282]\n"," [ 1.73955098  1.06980832 -0.96129792 ... -0.54350949 -0.25826497\n","  -1.58018604]]\n","shape for training set :  (135, 300) \n","shape for test set :  (59, 300) \n","shape for predicted set :  (8, 300)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"qGwuHogkYvct","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"JOXnxWbK6QOz","colab_type":"code","outputId":"bad14fa2-fd24-4579-afe9-4bb3fa4130cc","executionInfo":{"status":"ok","timestamp":1583492154175,"user_tz":-330,"elapsed":2315,"user":{"displayName":"Chinchili NagaGayathri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBwe3rdcMMP7AYp4wt-watfkQXNaXTZsR5jnmS=s64","userId":"00972754971743836265"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["import keras \n","from keras.models import Sequential, Model \n","from keras import layers\n","from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, Input, Embedding\n","from keras.layers.merge import Concatenate\n","\n","model1 = Sequential()\n"," \n","model1.add(Dense(128, activation='relu', input_dim=1000))\n","model1.add(Dropout(0.7))\n","model1.add(Dense(1, activation='sigmoid'))\n","model1.compile(optimizer='adadelta',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model1.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 128)               128128    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 128,257\n","Trainable params: 128,257\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OZ1o9woa73t2","colab_type":"code","outputId":"08739bae-63f6-4638-8880-4930e1a98651","executionInfo":{"status":"ok","timestamp":1583492159144,"user_tz":-330,"elapsed":2533,"user":{"displayName":"Chinchili NagaGayathri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBwe3rdcMMP7AYp4wt-watfkQXNaXTZsR5jnmS=s64","userId":"00972754971743836265"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import matplotlib.pyplot as plt\n","\n","history = model1.fit(train_vecs_w2v, y_train, epochs=40, batch_size=50,\n","                   validation_data=(test_vecs_w2v,y_test))\n","\n","loss, accuracy = model1.evaluate(train_vecs_w2v, y_train, verbose=False)\n","print(\"Training Accuracy: {:.4f}\".format(accuracy))\n","\n","\n","loss, accuracy = model1.evaluate(test_vecs_w2v, y_test, verbose=False)\n","print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n","\n","model1.save(\"/content/sample_data/myfirstmodel\", overwrite=True, include_optimizer=True)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 135 samples, validate on 59 samples\n","Epoch 1/40\n","135/135 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5556 - val_loss: 0.6929 - val_acc: 0.5424\n","Epoch 2/40\n","135/135 [==============================] - 0s 186us/step - loss: 0.6924 - acc: 0.6148 - val_loss: 0.6928 - val_acc: 0.5424\n","Epoch 3/40\n","135/135 [==============================] - 0s 173us/step - loss: 0.6919 - acc: 0.6148 - val_loss: 0.6926 - val_acc: 0.5424\n","Epoch 4/40\n","135/135 [==============================] - 0s 155us/step - loss: 0.6915 - acc: 0.6148 - val_loss: 0.6924 - val_acc: 0.5424\n","Epoch 5/40\n","135/135 [==============================] - 0s 159us/step - loss: 0.6911 - acc: 0.6148 - val_loss: 0.6923 - val_acc: 0.5424\n","Epoch 6/40\n","135/135 [==============================] - 0s 171us/step - loss: 0.6906 - acc: 0.6148 - val_loss: 0.6921 - val_acc: 0.5424\n","Epoch 7/40\n","135/135 [==============================] - 0s 144us/step - loss: 0.6902 - acc: 0.6148 - val_loss: 0.6920 - val_acc: 0.5424\n","Epoch 8/40\n","135/135 [==============================] - 0s 170us/step - loss: 0.6898 - acc: 0.6148 - val_loss: 0.6919 - val_acc: 0.5424\n","Epoch 9/40\n","135/135 [==============================] - 0s 153us/step - loss: 0.6894 - acc: 0.6148 - val_loss: 0.6917 - val_acc: 0.5424\n","Epoch 10/40\n","135/135 [==============================] - 0s 172us/step - loss: 0.6890 - acc: 0.6148 - val_loss: 0.6916 - val_acc: 0.5424\n","Epoch 11/40\n","135/135 [==============================] - 0s 186us/step - loss: 0.6886 - acc: 0.6148 - val_loss: 0.6915 - val_acc: 0.5424\n","Epoch 12/40\n","135/135 [==============================] - 0s 184us/step - loss: 0.6882 - acc: 0.6148 - val_loss: 0.6914 - val_acc: 0.5424\n","Epoch 13/40\n","135/135 [==============================] - 0s 153us/step - loss: 0.6878 - acc: 0.6148 - val_loss: 0.6913 - val_acc: 0.5424\n","Epoch 14/40\n","135/135 [==============================] - 0s 168us/step - loss: 0.6874 - acc: 0.6148 - val_loss: 0.6912 - val_acc: 0.5424\n","Epoch 15/40\n","135/135 [==============================] - 0s 170us/step - loss: 0.6870 - acc: 0.6148 - val_loss: 0.6910 - val_acc: 0.5424\n","Epoch 16/40\n","135/135 [==============================] - 0s 237us/step - loss: 0.6866 - acc: 0.6148 - val_loss: 0.6910 - val_acc: 0.5424\n","Epoch 17/40\n","135/135 [==============================] - 0s 183us/step - loss: 0.6863 - acc: 0.6148 - val_loss: 0.6909 - val_acc: 0.5424\n","Epoch 18/40\n","135/135 [==============================] - 0s 197us/step - loss: 0.6859 - acc: 0.6148 - val_loss: 0.6908 - val_acc: 0.5424\n","Epoch 19/40\n","135/135 [==============================] - 0s 161us/step - loss: 0.6855 - acc: 0.6148 - val_loss: 0.6907 - val_acc: 0.5424\n","Epoch 20/40\n","135/135 [==============================] - 0s 168us/step - loss: 0.6852 - acc: 0.6148 - val_loss: 0.6906 - val_acc: 0.5424\n","Epoch 21/40\n","135/135 [==============================] - 0s 177us/step - loss: 0.6848 - acc: 0.6148 - val_loss: 0.6905 - val_acc: 0.5424\n","Epoch 22/40\n","135/135 [==============================] - 0s 151us/step - loss: 0.6845 - acc: 0.6148 - val_loss: 0.6904 - val_acc: 0.5424\n","Epoch 23/40\n","135/135 [==============================] - 0s 169us/step - loss: 0.6842 - acc: 0.6148 - val_loss: 0.6904 - val_acc: 0.5424\n","Epoch 24/40\n","135/135 [==============================] - 0s 165us/step - loss: 0.6838 - acc: 0.6148 - val_loss: 0.6903 - val_acc: 0.5424\n","Epoch 25/40\n","135/135 [==============================] - 0s 150us/step - loss: 0.6835 - acc: 0.6148 - val_loss: 0.6902 - val_acc: 0.5424\n","Epoch 26/40\n","135/135 [==============================] - 0s 160us/step - loss: 0.6832 - acc: 0.6148 - val_loss: 0.6902 - val_acc: 0.5424\n","Epoch 27/40\n","135/135 [==============================] - 0s 163us/step - loss: 0.6829 - acc: 0.6148 - val_loss: 0.6901 - val_acc: 0.5424\n","Epoch 28/40\n","135/135 [==============================] - 0s 182us/step - loss: 0.6826 - acc: 0.6148 - val_loss: 0.6901 - val_acc: 0.5424\n","Epoch 29/40\n","135/135 [==============================] - 0s 185us/step - loss: 0.6823 - acc: 0.6148 - val_loss: 0.6900 - val_acc: 0.5424\n","Epoch 30/40\n","135/135 [==============================] - 0s 204us/step - loss: 0.6819 - acc: 0.6148 - val_loss: 0.6900 - val_acc: 0.5424\n","Epoch 31/40\n","135/135 [==============================] - 0s 211us/step - loss: 0.6817 - acc: 0.6148 - val_loss: 0.6899 - val_acc: 0.5424\n","Epoch 32/40\n","135/135 [==============================] - 0s 166us/step - loss: 0.6814 - acc: 0.6148 - val_loss: 0.6899 - val_acc: 0.5424\n","Epoch 33/40\n","135/135 [==============================] - 0s 144us/step - loss: 0.6811 - acc: 0.6148 - val_loss: 0.6898 - val_acc: 0.5424\n","Epoch 34/40\n","135/135 [==============================] - 0s 192us/step - loss: 0.6809 - acc: 0.6148 - val_loss: 0.6898 - val_acc: 0.5424\n","Epoch 35/40\n","135/135 [==============================] - 0s 158us/step - loss: 0.6806 - acc: 0.6148 - val_loss: 0.6898 - val_acc: 0.5424\n","Epoch 36/40\n","135/135 [==============================] - 0s 168us/step - loss: 0.6804 - acc: 0.6148 - val_loss: 0.6897 - val_acc: 0.5424\n","Epoch 37/40\n","135/135 [==============================] - 0s 227us/step - loss: 0.6802 - acc: 0.6148 - val_loss: 0.6897 - val_acc: 0.5424\n","Epoch 38/40\n","135/135 [==============================] - 0s 252us/step - loss: 0.6799 - acc: 0.6148 - val_loss: 0.6897 - val_acc: 0.5424\n","Epoch 39/40\n","135/135 [==============================] - 0s 190us/step - loss: 0.6797 - acc: 0.6148 - val_loss: 0.6897 - val_acc: 0.5424\n","Epoch 40/40\n","135/135 [==============================] - 0s 205us/step - loss: 0.6795 - acc: 0.6148 - val_loss: 0.6896 - val_acc: 0.5424\n","Training Accuracy: 0.6148\n","Testing Accuracy:  0.5424\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Nu3tHI573re","colab_type":"code","outputId":"d52fa48e-f497-4cf4-9031-c4b9cb9ae2e0","executionInfo":{"status":"error","timestamp":1583832559253,"user_tz":-330,"elapsed":1078,"user":{"displayName":"Chinchili NagaGayathri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBwe3rdcMMP7AYp4wt-watfkQXNaXTZsR5jnmS=s64","userId":"00972754971743836265"}},"colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["\n","l = model1.predict(pred_vec_w2v, verbose=True)\n","print(l)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-dd8994a45505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_vec_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"]}]},{"cell_type":"code","metadata":{"id":"tQeVCdRUHUMU","colab_type":"code","outputId":"ef87f4f3-36eb-4a79-dfa3-c8c5e2b628d3","executionInfo":{"status":"error","timestamp":1583493155543,"user_tz":-330,"elapsed":1119,"user":{"displayName":"Chinchili NagaGayathri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBwe3rdcMMP7AYp4wt-watfkQXNaXTZsR5jnmS=s64","userId":"00972754971743836265"}},"colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["~ ls"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-8ef1635fbc11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m~\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"]}]},{"cell_type":"code","metadata":{"id":"Zq5PMCp1gdHQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YmK5gmn_fv6u","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nF6Lt9tJgcsw","colab_type":"text"},"source":[""]}]}